

Steps to Create an AMI :

1.	Launch Instance
i.	Login to Amazon Web Services, click on My Account and navigate to Amazon EC2 Console
ii.	Select Launch instance and select Linux AMI
iii.	Set Instance Type to t2.micro which has a free tier eligible
iv.	Configure number of instances : As a 4 node cluster has to be set up select 4.
v.	Add storage to 8GB
vi.	Give the instance name and description (HadoopCluster)
vii.	Define security group rules such as SSH , TCP, etc or set to All Traffic
viii.	Review and Launch the instance and create a new security key pair an download this .pem file to your system  (HadoopMultiCluster_Rishi_Mamilla.pem)
ix.	Rename 4 instances once they are in “running state”
x.	HadoopNameNode (Master)
HadoopSecondaryNameNode ( Secondary Node)
HadoopSlave1(slave)
HadoopSlave2Node(slave)




2.	Setting up client access to Amazon instances 
To make sure we can connect to all 4 instances. For that Putty client is used.
We are going setup password-less SSH access among servers to setup the cluster. This allows remote access from Master Server to Slave Servers so Master Server can remotely start the Data Node and Task Tracker services on Slave servers.
i.	Generate a private key using PuttyGen and generate a .ppk key pair for the putty client and sace it
ii.	Connect to Amazon instance by importing the .ppk private key for a password-less SSH access and make sure to enter hostname and connect type and select port number 22
iii.	Launch the session and repeat for the SEcondaryNameNode and Slave instances .
iv.	Enable public access by issuing ipconfig and change hostname 
$ sudo hostname ec2-54-209-221-112.compute-1.amazonaws.com
We have successfully created, launched and connected to Amazon Linux AMI instances.


3. Hadoop Installation and Cluster Setup
i.  Update the packages and dependencies.
	$ sudo yum update
ii. Install Java
	$ sudo add-apt-repository ppa:webupd8team/java

	$ sudo apt-get update && sudo apt-get install oracle-jdk7-installer
iii. Download Hadoop
	$ wget http://apache.mirror.gtcomm.net/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz

	$ tar -xzvf hadoop-1.2.1.tar.gz
For simplicity, rename the ‘hadoop-1.2.1’ directory to ‘hadoop’ for ease of operation and maintenance.

$ mv hadoop-1.2.1 hadoop

iv. Set up environment variables

#Set JAVA_HOME

export JAVA_HOME=/usr/lib/jvm/java-7-oracle

# Add Hadoop bin/ directory to path
export PATH=$PATH:$HADOOP_PREFIX/bin

Save and Exit.

To check whether its been updated correctly or not, reload bash profile, use following commands

source ~/.bashrc
echo $HADOOP_PREFIX
echo $HADOOP_CONF

v.Setup Password-less SSH on Servers
	$ chmod 644 authorized_keys
	$ chmod 400 HadoopMultiCluster.pem
vi. To use ssh-agent and ssh-add, follow the steps below:

>At the Unix prompt, enter: eval `ssh-agent`Note: Make sure you use the backquote ( ` ), located under the tilde ( ~ ), rather than the single quote ( ' ).
>Enter the command: ssh-add HadoopMultiCluster.pem


4. Hadoop Cluster set up
  Following files are modified:

     (a) $HADOOP_CONF_DIR/hadoop-env.sh

     # Change the location of JAVA_HOME. The java implementation to use.
     export JAVA_HOME=/usr

     (b) $HADOOP_CONF_DIR/core-site.xml (Declare the Hadoop File System, replace 'namenode_public_dns' with actual Public DNS of instances )
     
     <configuration>
     <property>
      <name>fs.defaultFS</name>
      <value>hdfs://namenode_public_dns:9000</value>
    </property>
    </configuration>
     
     (c) $HADOOP_CONF_DIR/yarn-site.xml (Declare location of Resource Manager, replace 'namenode_public_dns' with actual Public DNS of instances)
         <configuration>
         <property>
           <name>yarn.nodemanager.aux-services</name>
           <value>mapreduce_shuffle</value>
        </property> 
        <property>
          <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
          <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
        <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>namenode_public_dns</value>
        </property>
        </configuration>

     (d) $HADOOP_CONF_DIR/mapred-site.xml (Create a copy of the template, Declare location of Job Tracker, replace 'namenode_public_dns' with actual Public DNS of instances)
       
         sudo cp $HADOOP_CONF_DIR/mapred-site.xml.template $HADOOP_CONF_DIR/mapred-site.xml

         <configuration>
         <property>
           <name>mapreduce.jobtracker.address</name>
           <value>namenode_public_dns:54311</value>
         </property>
         <property>
           <name>mapreduce.framework.name</name>
           <value>yarn</value>
         </property>
         </configuration>





